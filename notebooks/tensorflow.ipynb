{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'/Users/badr/Documents/ETS/Hiv2021/PFE/VS/git/fake-news-detection/notebooks'"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_repository = os.path.join(cwd, os.pardir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.join(main_repository, 'src'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Tensorflow Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_model.TensorflowModel import TensorflowModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tensorflow = TensorflowModel(main_repository, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tensorflow.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:48<00:00, 21.67s/it]\n"
     ]
    }
   ],
   "source": [
    "Tensorflow.format()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28746 files belonging to 2 classes.\n",
      "Found 7188 files belonging to 2 classes.\n",
      "Epoch 1/40\n",
      "899/899 [==============================] - 20s 22ms/step - loss: 0.5701 - binary_accuracy: 0.7720 - val_loss: 0.5039 - val_binary_accuracy: 0.6779\n",
      "Epoch 2/40\n",
      "899/899 [==============================] - 3s 3ms/step - loss: 0.2012 - binary_accuracy: 0.9445 - val_loss: 0.4410 - val_binary_accuracy: 0.7440\n",
      "Epoch 3/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.1289 - binary_accuracy: 0.9605 - val_loss: 0.3659 - val_binary_accuracy: 0.8118\n",
      "Epoch 4/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0979 - binary_accuracy: 0.9687 - val_loss: 0.2862 - val_binary_accuracy: 0.8676\n",
      "Epoch 5/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0798 - binary_accuracy: 0.9743 - val_loss: 0.2351 - val_binary_accuracy: 0.9014\n",
      "Epoch 6/40\n",
      "899/899 [==============================] - 2s 2ms/step - loss: 0.0671 - binary_accuracy: 0.9786 - val_loss: 0.1954 - val_binary_accuracy: 0.9239\n",
      "Epoch 7/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0585 - binary_accuracy: 0.9816 - val_loss: 0.1637 - val_binary_accuracy: 0.9392\n",
      "Epoch 8/40\n",
      "899/899 [==============================] - 2s 2ms/step - loss: 0.0525 - binary_accuracy: 0.9837 - val_loss: 0.1432 - val_binary_accuracy: 0.9509\n",
      "Epoch 9/40\n",
      "899/899 [==============================] - 2s 2ms/step - loss: 0.0485 - binary_accuracy: 0.9846 - val_loss: 0.1271 - val_binary_accuracy: 0.9569\n",
      "Epoch 10/40\n",
      "899/899 [==============================] - 2s 2ms/step - loss: 0.0439 - binary_accuracy: 0.9864 - val_loss: 0.1195 - val_binary_accuracy: 0.9598\n",
      "Epoch 11/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0429 - binary_accuracy: 0.9868 - val_loss: 0.1100 - val_binary_accuracy: 0.9634\n",
      "Epoch 12/40\n",
      "899/899 [==============================] - 2s 2ms/step - loss: 0.0409 - binary_accuracy: 0.9870 - val_loss: 0.1051 - val_binary_accuracy: 0.9661\n",
      "Epoch 13/40\n",
      "899/899 [==============================] - 2s 2ms/step - loss: 0.0398 - binary_accuracy: 0.9877 - val_loss: 0.1059 - val_binary_accuracy: 0.9659\n",
      "Epoch 14/40\n",
      "899/899 [==============================] - 2s 2ms/step - loss: 0.0383 - binary_accuracy: 0.9883 - val_loss: 0.0994 - val_binary_accuracy: 0.9688\n",
      "Epoch 15/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0382 - binary_accuracy: 0.9884 - val_loss: 0.0986 - val_binary_accuracy: 0.9693\n",
      "Epoch 16/40\n",
      "899/899 [==============================] - 3s 3ms/step - loss: 0.0377 - binary_accuracy: 0.9891 - val_loss: 0.0995 - val_binary_accuracy: 0.9698\n",
      "Epoch 17/40\n",
      "899/899 [==============================] - 3s 3ms/step - loss: 0.0374 - binary_accuracy: 0.9889 - val_loss: 0.0981 - val_binary_accuracy: 0.9698\n",
      "Epoch 18/40\n",
      "899/899 [==============================] - 3s 3ms/step - loss: 0.0374 - binary_accuracy: 0.9889 - val_loss: 0.0991 - val_binary_accuracy: 0.9699\n",
      "Epoch 19/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0365 - binary_accuracy: 0.9887 - val_loss: 0.0950 - val_binary_accuracy: 0.9713\n",
      "Epoch 20/40\n",
      "899/899 [==============================] - 3s 3ms/step - loss: 0.0367 - binary_accuracy: 0.9890 - val_loss: 0.0975 - val_binary_accuracy: 0.9704\n",
      "Epoch 21/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0351 - binary_accuracy: 0.9894 - val_loss: 0.0962 - val_binary_accuracy: 0.9713\n",
      "Epoch 22/40\n",
      "899/899 [==============================] - 3s 3ms/step - loss: 0.0359 - binary_accuracy: 0.9888 - val_loss: 0.0997 - val_binary_accuracy: 0.9695\n",
      "Epoch 23/40\n",
      "899/899 [==============================] - 3s 3ms/step - loss: 0.0356 - binary_accuracy: 0.9894 - val_loss: 0.0957 - val_binary_accuracy: 0.9718\n",
      "Epoch 24/40\n",
      "899/899 [==============================] - 3s 3ms/step - loss: 0.0344 - binary_accuracy: 0.9899 - val_loss: 0.0955 - val_binary_accuracy: 0.9720\n",
      "Epoch 25/40\n",
      "899/899 [==============================] - 2s 2ms/step - loss: 0.0352 - binary_accuracy: 0.9892 - val_loss: 0.0998 - val_binary_accuracy: 0.9699\n",
      "Epoch 26/40\n",
      "899/899 [==============================] - 3s 3ms/step - loss: 0.0345 - binary_accuracy: 0.9892 - val_loss: 0.0996 - val_binary_accuracy: 0.9704\n",
      "Epoch 27/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0345 - binary_accuracy: 0.9894 - val_loss: 0.0964 - val_binary_accuracy: 0.9715\n",
      "Epoch 28/40\n",
      "899/899 [==============================] - 3s 3ms/step - loss: 0.0347 - binary_accuracy: 0.9891 - val_loss: 0.0996 - val_binary_accuracy: 0.9705\n",
      "Epoch 29/40\n",
      "899/899 [==============================] - 3s 3ms/step - loss: 0.0348 - binary_accuracy: 0.9888 - val_loss: 0.0993 - val_binary_accuracy: 0.9705\n",
      "Epoch 30/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0354 - binary_accuracy: 0.9887 - val_loss: 0.0973 - val_binary_accuracy: 0.9709\n",
      "Epoch 31/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0352 - binary_accuracy: 0.9890 - val_loss: 0.0965 - val_binary_accuracy: 0.9712\n",
      "Epoch 32/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0338 - binary_accuracy: 0.9896 - val_loss: 0.0978 - val_binary_accuracy: 0.9709\n",
      "Epoch 33/40\n",
      "899/899 [==============================] - 3s 3ms/step - loss: 0.0344 - binary_accuracy: 0.9890 - val_loss: 0.0986 - val_binary_accuracy: 0.9708\n",
      "Epoch 34/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0349 - binary_accuracy: 0.9892 - val_loss: 0.0996 - val_binary_accuracy: 0.9708\n",
      "Epoch 35/40\n",
      "899/899 [==============================] - 3s 3ms/step - loss: 0.0345 - binary_accuracy: 0.9893 - val_loss: 0.1004 - val_binary_accuracy: 0.9704\n",
      "Epoch 36/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0337 - binary_accuracy: 0.9887 - val_loss: 0.0989 - val_binary_accuracy: 0.9705\n",
      "Epoch 37/40\n",
      "899/899 [==============================] - 3s 3ms/step - loss: 0.0346 - binary_accuracy: 0.9885 - val_loss: 0.0975 - val_binary_accuracy: 0.9705\n",
      "Epoch 38/40\n",
      "899/899 [==============================] - 3s 3ms/step - loss: 0.0342 - binary_accuracy: 0.9893 - val_loss: 0.0996 - val_binary_accuracy: 0.9702\n",
      "Epoch 39/40\n",
      "899/899 [==============================] - 3s 3ms/step - loss: 0.0344 - binary_accuracy: 0.9890 - val_loss: 0.0973 - val_binary_accuracy: 0.9709\n",
      "Epoch 40/40\n",
      "899/899 [==============================] - 3s 3ms/step - loss: 0.0348 - binary_accuracy: 0.9886 - val_loss: 0.1007 - val_binary_accuracy: 0.9701\n",
      "225/225 [==============================] - 6s 20ms/step - loss: 0.0913 - accuracy: 0.9701 - precision_30: 0.9919\n",
      "INFO:tensorflow:Assets written to: /Users/badr/Documents/ETS/Hiv2021/PFE/VS/git/fake-news-detection/notebooks/../models/tensorflow/model_1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [02:24<09:38, 144.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28746 files belonging to 2 classes.\n",
      "Found 7188 files belonging to 2 classes.\n",
      "Epoch 1/40\n",
      "899/899 [==============================] - 18s 19ms/step - loss: 0.5670 - binary_accuracy: 0.7744 - val_loss: 0.4870 - val_binary_accuracy: 0.6967\n",
      "Epoch 2/40\n",
      "899/899 [==============================] - 2s 2ms/step - loss: 0.2004 - binary_accuracy: 0.9472 - val_loss: 0.4341 - val_binary_accuracy: 0.7564\n",
      "Epoch 3/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.1275 - binary_accuracy: 0.9632 - val_loss: 0.3790 - val_binary_accuracy: 0.8027\n",
      "Epoch 4/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0966 - binary_accuracy: 0.9711 - val_loss: 0.3359 - val_binary_accuracy: 0.8357\n",
      "Epoch 5/40\n",
      "899/899 [==============================] - 2s 2ms/step - loss: 0.0773 - binary_accuracy: 0.9749 - val_loss: 0.2922 - val_binary_accuracy: 0.8656\n",
      "Epoch 6/40\n",
      "899/899 [==============================] - 3s 3ms/step - loss: 0.0660 - binary_accuracy: 0.9785 - val_loss: 0.2466 - val_binary_accuracy: 0.8959\n",
      "Epoch 7/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0568 - binary_accuracy: 0.9803 - val_loss: 0.2089 - val_binary_accuracy: 0.9171\n",
      "Epoch 8/40\n",
      "899/899 [==============================] - 3s 3ms/step - loss: 0.0506 - binary_accuracy: 0.9837 - val_loss: 0.1907 - val_binary_accuracy: 0.9290\n",
      "Epoch 9/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0463 - binary_accuracy: 0.9850 - val_loss: 0.1625 - val_binary_accuracy: 0.9452\n",
      "Epoch 10/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0430 - binary_accuracy: 0.9863 - val_loss: 0.1560 - val_binary_accuracy: 0.9492\n",
      "Epoch 11/40\n",
      "899/899 [==============================] - 3s 3ms/step - loss: 0.0403 - binary_accuracy: 0.9868 - val_loss: 0.1423 - val_binary_accuracy: 0.9549\n",
      "Epoch 12/40\n",
      "899/899 [==============================] - 3s 3ms/step - loss: 0.0389 - binary_accuracy: 0.9873 - val_loss: 0.1359 - val_binary_accuracy: 0.9572\n",
      "Epoch 13/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0385 - binary_accuracy: 0.9875 - val_loss: 0.1355 - val_binary_accuracy: 0.9590\n",
      "Epoch 14/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0368 - binary_accuracy: 0.9881 - val_loss: 0.1252 - val_binary_accuracy: 0.9616\n",
      "Epoch 15/40\n",
      "899/899 [==============================] - 2s 2ms/step - loss: 0.0360 - binary_accuracy: 0.9883 - val_loss: 0.1281 - val_binary_accuracy: 0.9609\n",
      "Epoch 16/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0359 - binary_accuracy: 0.9891 - val_loss: 0.1242 - val_binary_accuracy: 0.9623\n",
      "Epoch 17/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0349 - binary_accuracy: 0.9888 - val_loss: 0.1178 - val_binary_accuracy: 0.9636\n",
      "Epoch 18/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0343 - binary_accuracy: 0.9898 - val_loss: 0.1229 - val_binary_accuracy: 0.9626\n",
      "Epoch 19/40\n",
      "899/899 [==============================] - 3s 3ms/step - loss: 0.0337 - binary_accuracy: 0.9896 - val_loss: 0.1153 - val_binary_accuracy: 0.9642\n",
      "Epoch 20/40\n",
      "899/899 [==============================] - 3s 3ms/step - loss: 0.0335 - binary_accuracy: 0.9900 - val_loss: 0.1182 - val_binary_accuracy: 0.9634\n",
      "Epoch 21/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0337 - binary_accuracy: 0.9900 - val_loss: 0.1189 - val_binary_accuracy: 0.9637\n",
      "Epoch 22/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0330 - binary_accuracy: 0.9895 - val_loss: 0.1185 - val_binary_accuracy: 0.9638\n",
      "Epoch 23/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0326 - binary_accuracy: 0.9894 - val_loss: 0.1127 - val_binary_accuracy: 0.9651\n",
      "Epoch 24/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0329 - binary_accuracy: 0.9904 - val_loss: 0.1133 - val_binary_accuracy: 0.9649\n",
      "Epoch 25/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0329 - binary_accuracy: 0.9900 - val_loss: 0.1124 - val_binary_accuracy: 0.9649\n",
      "Epoch 26/40\n",
      "899/899 [==============================] - 2s 2ms/step - loss: 0.0320 - binary_accuracy: 0.9901 - val_loss: 0.1141 - val_binary_accuracy: 0.9648\n",
      "Epoch 27/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0323 - binary_accuracy: 0.9900 - val_loss: 0.1127 - val_binary_accuracy: 0.9652\n",
      "Epoch 28/40\n",
      "899/899 [==============================] - 3s 3ms/step - loss: 0.0321 - binary_accuracy: 0.9897 - val_loss: 0.1157 - val_binary_accuracy: 0.9654\n",
      "Epoch 29/40\n",
      "899/899 [==============================] - 3s 3ms/step - loss: 0.0314 - binary_accuracy: 0.9905 - val_loss: 0.1137 - val_binary_accuracy: 0.9654\n",
      "Epoch 30/40\n",
      "899/899 [==============================] - 2s 2ms/step - loss: 0.0315 - binary_accuracy: 0.9899 - val_loss: 0.1145 - val_binary_accuracy: 0.9654\n",
      "Epoch 31/40\n",
      "899/899 [==============================] - 3s 3ms/step - loss: 0.0320 - binary_accuracy: 0.9904 - val_loss: 0.1147 - val_binary_accuracy: 0.9654\n",
      "Epoch 32/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0322 - binary_accuracy: 0.9898 - val_loss: 0.1124 - val_binary_accuracy: 0.9652\n",
      "Epoch 33/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0308 - binary_accuracy: 0.9908 - val_loss: 0.1129 - val_binary_accuracy: 0.9655\n",
      "Epoch 34/40\n",
      "899/899 [==============================] - 2s 2ms/step - loss: 0.0322 - binary_accuracy: 0.9897 - val_loss: 0.1156 - val_binary_accuracy: 0.9655\n",
      "Epoch 35/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0299 - binary_accuracy: 0.9908 - val_loss: 0.1172 - val_binary_accuracy: 0.9649\n",
      "Epoch 36/40\n",
      "899/899 [==============================] - 2s 2ms/step - loss: 0.0313 - binary_accuracy: 0.9899 - val_loss: 0.1134 - val_binary_accuracy: 0.9658\n",
      "Epoch 37/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0315 - binary_accuracy: 0.9904 - val_loss: 0.1077 - val_binary_accuracy: 0.9665\n",
      "Epoch 38/40\n",
      "899/899 [==============================] - 2s 2ms/step - loss: 0.0312 - binary_accuracy: 0.9907 - val_loss: 0.1148 - val_binary_accuracy: 0.9655\n",
      "Epoch 39/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0315 - binary_accuracy: 0.9900 - val_loss: 0.1120 - val_binary_accuracy: 0.9661\n",
      "Epoch 40/40\n",
      "899/899 [==============================] - 3s 3ms/step - loss: 0.0317 - binary_accuracy: 0.9904 - val_loss: 0.1159 - val_binary_accuracy: 0.9654\n",
      "225/225 [==============================] - 5s 18ms/step - loss: 0.1101 - accuracy: 0.9679 - precision_31: 0.9959\n",
      "INFO:tensorflow:Assets written to: /Users/badr/Documents/ETS/Hiv2021/PFE/VS/git/fake-news-detection/notebooks/../models/tensorflow/model_2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [04:41<07:00, 140.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28748 files belonging to 2 classes.\n",
      "Found 7188 files belonging to 2 classes.\n",
      "Epoch 1/40\n",
      "899/899 [==============================] - 18s 19ms/step - loss: 0.5652 - binary_accuracy: 0.7521 - val_loss: 0.4792 - val_binary_accuracy: 0.7104\n",
      "Epoch 2/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.1978 - binary_accuracy: 0.9476 - val_loss: 0.4144 - val_binary_accuracy: 0.7735\n",
      "Epoch 3/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.1273 - binary_accuracy: 0.9626 - val_loss: 0.3591 - val_binary_accuracy: 0.8223\n",
      "Epoch 4/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0972 - binary_accuracy: 0.9703 - val_loss: 0.2979 - val_binary_accuracy: 0.8616\n",
      "Epoch 5/40\n",
      "899/899 [==============================] - 2s 2ms/step - loss: 0.0788 - binary_accuracy: 0.9754 - val_loss: 0.2573 - val_binary_accuracy: 0.8881\n",
      "Epoch 6/40\n",
      "899/899 [==============================] - 2s 2ms/step - loss: 0.0657 - binary_accuracy: 0.9791 - val_loss: 0.2181 - val_binary_accuracy: 0.9118\n",
      "Epoch 7/40\n",
      "899/899 [==============================] - 2s 2ms/step - loss: 0.0568 - binary_accuracy: 0.9821 - val_loss: 0.1916 - val_binary_accuracy: 0.9284\n",
      "Epoch 8/40\n",
      "899/899 [==============================] - 2s 2ms/step - loss: 0.0502 - binary_accuracy: 0.9844 - val_loss: 0.1770 - val_binary_accuracy: 0.9370\n",
      "Epoch 9/40\n",
      "899/899 [==============================] - 2s 2ms/step - loss: 0.0456 - binary_accuracy: 0.9853 - val_loss: 0.1644 - val_binary_accuracy: 0.9435\n",
      "Epoch 10/40\n",
      "899/899 [==============================] - 2s 2ms/step - loss: 0.0414 - binary_accuracy: 0.9870 - val_loss: 0.1600 - val_binary_accuracy: 0.9476\n",
      "Epoch 11/40\n",
      "899/899 [==============================] - 2s 2ms/step - loss: 0.0395 - binary_accuracy: 0.9871 - val_loss: 0.1493 - val_binary_accuracy: 0.9519\n",
      "Epoch 12/40\n",
      "899/899 [==============================] - 2s 2ms/step - loss: 0.0377 - binary_accuracy: 0.9877 - val_loss: 0.1366 - val_binary_accuracy: 0.9556\n",
      "Epoch 13/40\n",
      "899/899 [==============================] - 2s 2ms/step - loss: 0.0348 - binary_accuracy: 0.9885 - val_loss: 0.1437 - val_binary_accuracy: 0.9545\n",
      "Epoch 14/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0341 - binary_accuracy: 0.9891 - val_loss: 0.1386 - val_binary_accuracy: 0.9563\n",
      "Epoch 15/40\n",
      "899/899 [==============================] - 2s 2ms/step - loss: 0.0333 - binary_accuracy: 0.9892 - val_loss: 0.1389 - val_binary_accuracy: 0.9566\n",
      "Epoch 16/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0325 - binary_accuracy: 0.9897 - val_loss: 0.1316 - val_binary_accuracy: 0.9591\n",
      "Epoch 17/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0322 - binary_accuracy: 0.9894 - val_loss: 0.1283 - val_binary_accuracy: 0.9605\n",
      "Epoch 18/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0310 - binary_accuracy: 0.9894 - val_loss: 0.1328 - val_binary_accuracy: 0.9598\n",
      "Epoch 19/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0313 - binary_accuracy: 0.9899 - val_loss: 0.1340 - val_binary_accuracy: 0.9604\n",
      "Epoch 20/40\n",
      "899/899 [==============================] - 2s 2ms/step - loss: 0.0304 - binary_accuracy: 0.9901 - val_loss: 0.1346 - val_binary_accuracy: 0.9602\n",
      "Epoch 21/40\n",
      "899/899 [==============================] - 2s 2ms/step - loss: 0.0303 - binary_accuracy: 0.9904 - val_loss: 0.1380 - val_binary_accuracy: 0.9598\n",
      "Epoch 22/40\n",
      "899/899 [==============================] - 2s 2ms/step - loss: 0.0299 - binary_accuracy: 0.9899 - val_loss: 0.1342 - val_binary_accuracy: 0.9608\n",
      "Epoch 23/40\n",
      "899/899 [==============================] - 2s 2ms/step - loss: 0.0296 - binary_accuracy: 0.9906 - val_loss: 0.1305 - val_binary_accuracy: 0.9617\n",
      "Epoch 24/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0293 - binary_accuracy: 0.9904 - val_loss: 0.1383 - val_binary_accuracy: 0.9602\n",
      "Epoch 25/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0296 - binary_accuracy: 0.9905 - val_loss: 0.1379 - val_binary_accuracy: 0.9605\n",
      "Epoch 26/40\n",
      "899/899 [==============================] - 3s 3ms/step - loss: 0.0294 - binary_accuracy: 0.9899 - val_loss: 0.1336 - val_binary_accuracy: 0.9615\n",
      "Epoch 27/40\n",
      "899/899 [==============================] - 3s 3ms/step - loss: 0.0291 - binary_accuracy: 0.9901 - val_loss: 0.1398 - val_binary_accuracy: 0.9604\n",
      "Epoch 28/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0295 - binary_accuracy: 0.9898 - val_loss: 0.1321 - val_binary_accuracy: 0.9624\n",
      "Epoch 29/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0285 - binary_accuracy: 0.9908 - val_loss: 0.1404 - val_binary_accuracy: 0.9604\n",
      "Epoch 30/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0286 - binary_accuracy: 0.9901 - val_loss: 0.1313 - val_binary_accuracy: 0.9627\n",
      "Epoch 31/40\n",
      "899/899 [==============================] - 2s 2ms/step - loss: 0.0288 - binary_accuracy: 0.9905 - val_loss: 0.1322 - val_binary_accuracy: 0.9626\n",
      "Epoch 32/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0279 - binary_accuracy: 0.9904 - val_loss: 0.1461 - val_binary_accuracy: 0.9595\n",
      "Epoch 33/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0289 - binary_accuracy: 0.9901 - val_loss: 0.1307 - val_binary_accuracy: 0.9630\n",
      "Epoch 34/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0288 - binary_accuracy: 0.9899 - val_loss: 0.1335 - val_binary_accuracy: 0.9629\n",
      "Epoch 35/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0283 - binary_accuracy: 0.9909 - val_loss: 0.1368 - val_binary_accuracy: 0.9623\n",
      "Epoch 36/40\n",
      "899/899 [==============================] - 2s 2ms/step - loss: 0.0273 - binary_accuracy: 0.9913 - val_loss: 0.1415 - val_binary_accuracy: 0.9608\n",
      "Epoch 37/40\n",
      "899/899 [==============================] - 2s 2ms/step - loss: 0.0281 - binary_accuracy: 0.9908 - val_loss: 0.1418 - val_binary_accuracy: 0.9610\n",
      "Epoch 38/40\n",
      "899/899 [==============================] - 2s 2ms/step - loss: 0.0276 - binary_accuracy: 0.9909 - val_loss: 0.1406 - val_binary_accuracy: 0.9612\n",
      "Epoch 39/40\n",
      "899/899 [==============================] - 2s 2ms/step - loss: 0.0286 - binary_accuracy: 0.9900 - val_loss: 0.1404 - val_binary_accuracy: 0.9617\n",
      "Epoch 40/40\n",
      "899/899 [==============================] - 2s 2ms/step - loss: 0.0293 - binary_accuracy: 0.9905 - val_loss: 0.1443 - val_binary_accuracy: 0.9606\n",
      "225/225 [==============================] - 4s 14ms/step - loss: 0.1433 - accuracy: 0.9608 - precision_32: 0.9955\n",
      "INFO:tensorflow:Assets written to: /Users/badr/Documents/ETS/Hiv2021/PFE/VS/git/fake-news-detection/notebooks/../models/tensorflow/model_3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [06:50<04:30, 135.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28748 files belonging to 2 classes.\n",
      "Found 7188 files belonging to 2 classes.\n",
      "Epoch 1/40\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.5683 - binary_accuracy: 0.7250 - val_loss: 0.4818 - val_binary_accuracy: 0.7042\n",
      "Epoch 2/40\n",
      "899/899 [==============================] - 2s 2ms/step - loss: 0.2008 - binary_accuracy: 0.9460 - val_loss: 0.4286 - val_binary_accuracy: 0.7581\n",
      "Epoch 3/40\n",
      "899/899 [==============================] - 1s 2ms/step - loss: 0.1292 - binary_accuracy: 0.9593 - val_loss: 0.3622 - val_binary_accuracy: 0.8143\n",
      "Epoch 4/40\n",
      "899/899 [==============================] - 1s 2ms/step - loss: 0.0986 - binary_accuracy: 0.9679 - val_loss: 0.3091 - val_binary_accuracy: 0.8534\n",
      "Epoch 5/40\n",
      "899/899 [==============================] - 1s 2ms/step - loss: 0.0806 - binary_accuracy: 0.9735 - val_loss: 0.2515 - val_binary_accuracy: 0.8881\n",
      "Epoch 6/40\n",
      "899/899 [==============================] - 2s 2ms/step - loss: 0.0680 - binary_accuracy: 0.9768 - val_loss: 0.2103 - val_binary_accuracy: 0.9126\n",
      "Epoch 7/40\n",
      "899/899 [==============================] - 2s 2ms/step - loss: 0.0595 - binary_accuracy: 0.9796 - val_loss: 0.1835 - val_binary_accuracy: 0.9285\n",
      "Epoch 8/40\n",
      "899/899 [==============================] - 2s 2ms/step - loss: 0.0531 - binary_accuracy: 0.9820 - val_loss: 0.1649 - val_binary_accuracy: 0.9388\n",
      "Epoch 9/40\n",
      "899/899 [==============================] - 2s 2ms/step - loss: 0.0496 - binary_accuracy: 0.9834 - val_loss: 0.1525 - val_binary_accuracy: 0.9449\n",
      "Epoch 10/40\n",
      "899/899 [==============================] - 2s 2ms/step - loss: 0.0454 - binary_accuracy: 0.9840 - val_loss: 0.1398 - val_binary_accuracy: 0.9519\n",
      "Epoch 11/40\n",
      "899/899 [==============================] - 1s 2ms/step - loss: 0.0427 - binary_accuracy: 0.9856 - val_loss: 0.1282 - val_binary_accuracy: 0.9567\n",
      "Epoch 12/40\n",
      "899/899 [==============================] - 1s 2ms/step - loss: 0.0418 - binary_accuracy: 0.9867 - val_loss: 0.1251 - val_binary_accuracy: 0.9584\n",
      "Epoch 13/40\n",
      "899/899 [==============================] - 1s 2ms/step - loss: 0.0403 - binary_accuracy: 0.9870 - val_loss: 0.1202 - val_binary_accuracy: 0.9598\n",
      "Epoch 14/40\n",
      "899/899 [==============================] - 1s 2ms/step - loss: 0.0387 - binary_accuracy: 0.9875 - val_loss: 0.1164 - val_binary_accuracy: 0.9612\n",
      "Epoch 15/40\n",
      "899/899 [==============================] - 1s 2ms/step - loss: 0.0371 - binary_accuracy: 0.9880 - val_loss: 0.1144 - val_binary_accuracy: 0.9620\n",
      "Epoch 16/40\n",
      "899/899 [==============================] - 1s 2ms/step - loss: 0.0368 - binary_accuracy: 0.9876 - val_loss: 0.1176 - val_binary_accuracy: 0.9619\n",
      "Epoch 17/40\n",
      "899/899 [==============================] - 1s 2ms/step - loss: 0.0363 - binary_accuracy: 0.9889 - val_loss: 0.1186 - val_binary_accuracy: 0.9619\n",
      "Epoch 18/40\n",
      "899/899 [==============================] - 1s 2ms/step - loss: 0.0365 - binary_accuracy: 0.9882 - val_loss: 0.1094 - val_binary_accuracy: 0.9649\n",
      "Epoch 19/40\n",
      "899/899 [==============================] - 1s 2ms/step - loss: 0.0358 - binary_accuracy: 0.9888 - val_loss: 0.1155 - val_binary_accuracy: 0.9640\n",
      "Epoch 20/40\n",
      "899/899 [==============================] - 1s 2ms/step - loss: 0.0341 - binary_accuracy: 0.9882 - val_loss: 0.1147 - val_binary_accuracy: 0.9645\n",
      "Epoch 21/40\n",
      "899/899 [==============================] - 1s 2ms/step - loss: 0.0352 - binary_accuracy: 0.9886 - val_loss: 0.1129 - val_binary_accuracy: 0.9649\n",
      "Epoch 22/40\n",
      "899/899 [==============================] - 1s 2ms/step - loss: 0.0346 - binary_accuracy: 0.9887 - val_loss: 0.1128 - val_binary_accuracy: 0.9652\n",
      "Epoch 23/40\n",
      "899/899 [==============================] - 1s 2ms/step - loss: 0.0344 - binary_accuracy: 0.9891 - val_loss: 0.1185 - val_binary_accuracy: 0.9641\n",
      "Epoch 24/40\n",
      "899/899 [==============================] - 1s 2ms/step - loss: 0.0337 - binary_accuracy: 0.9891 - val_loss: 0.1160 - val_binary_accuracy: 0.9647\n",
      "Epoch 25/40\n",
      "899/899 [==============================] - 1s 2ms/step - loss: 0.0334 - binary_accuracy: 0.9891 - val_loss: 0.1132 - val_binary_accuracy: 0.9654\n",
      "Epoch 26/40\n",
      "899/899 [==============================] - 1s 2ms/step - loss: 0.0334 - binary_accuracy: 0.9891 - val_loss: 0.1091 - val_binary_accuracy: 0.9663\n",
      "Epoch 27/40\n",
      "899/899 [==============================] - 1s 2ms/step - loss: 0.0332 - binary_accuracy: 0.9892 - val_loss: 0.1130 - val_binary_accuracy: 0.9656\n",
      "Epoch 28/40\n",
      "899/899 [==============================] - 1s 2ms/step - loss: 0.0341 - binary_accuracy: 0.9882 - val_loss: 0.1154 - val_binary_accuracy: 0.9652\n",
      "Epoch 29/40\n",
      "899/899 [==============================] - 1s 2ms/step - loss: 0.0333 - binary_accuracy: 0.9886 - val_loss: 0.1118 - val_binary_accuracy: 0.9662\n",
      "Epoch 30/40\n",
      "899/899 [==============================] - 1s 2ms/step - loss: 0.0334 - binary_accuracy: 0.9894 - val_loss: 0.1134 - val_binary_accuracy: 0.9658\n",
      "Epoch 31/40\n",
      "899/899 [==============================] - 1s 2ms/step - loss: 0.0331 - binary_accuracy: 0.9892 - val_loss: 0.1172 - val_binary_accuracy: 0.9651\n",
      "Epoch 32/40\n",
      "899/899 [==============================] - 1s 2ms/step - loss: 0.0339 - binary_accuracy: 0.9891 - val_loss: 0.1111 - val_binary_accuracy: 0.9661\n",
      "Epoch 33/40\n",
      "899/899 [==============================] - 2s 2ms/step - loss: 0.0322 - binary_accuracy: 0.9892 - val_loss: 0.1129 - val_binary_accuracy: 0.9659\n",
      "Epoch 34/40\n",
      "899/899 [==============================] - 1s 2ms/step - loss: 0.0325 - binary_accuracy: 0.9894 - val_loss: 0.1156 - val_binary_accuracy: 0.9654\n",
      "Epoch 35/40\n",
      "899/899 [==============================] - 1s 2ms/step - loss: 0.0331 - binary_accuracy: 0.9892 - val_loss: 0.1135 - val_binary_accuracy: 0.9661\n",
      "Epoch 36/40\n",
      "899/899 [==============================] - 1s 2ms/step - loss: 0.0333 - binary_accuracy: 0.9887 - val_loss: 0.1150 - val_binary_accuracy: 0.9658\n",
      "Epoch 37/40\n",
      "899/899 [==============================] - 2s 2ms/step - loss: 0.0337 - binary_accuracy: 0.9889 - val_loss: 0.1169 - val_binary_accuracy: 0.9656\n",
      "Epoch 38/40\n",
      "899/899 [==============================] - 2s 2ms/step - loss: 0.0317 - binary_accuracy: 0.9890 - val_loss: 0.1128 - val_binary_accuracy: 0.9663\n",
      "Epoch 39/40\n",
      "899/899 [==============================] - 1s 2ms/step - loss: 0.0338 - binary_accuracy: 0.9894 - val_loss: 0.1114 - val_binary_accuracy: 0.9669\n",
      "Epoch 40/40\n",
      "899/899 [==============================] - 1s 2ms/step - loss: 0.0326 - binary_accuracy: 0.9894 - val_loss: 0.1130 - val_binary_accuracy: 0.9665\n",
      "225/225 [==============================] - 3s 13ms/step - loss: 0.1157 - accuracy: 0.9685 - precision_33: 0.9968\n",
      "INFO:tensorflow:Assets written to: /Users/badr/Documents/ETS/Hiv2021/PFE/VS/git/fake-news-detection/notebooks/../models/tensorflow/model_4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [08:23<01:58, 118.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28748 files belonging to 2 classes.\n",
      "Found 7188 files belonging to 2 classes.\n",
      "Epoch 1/40\n",
      "899/899 [==============================] - 18s 19ms/step - loss: 0.5655 - binary_accuracy: 0.7446 - val_loss: 0.4767 - val_binary_accuracy: 0.7166\n",
      "Epoch 2/40\n",
      "899/899 [==============================] - 2s 2ms/step - loss: 0.1999 - binary_accuracy: 0.9472 - val_loss: 0.4104 - val_binary_accuracy: 0.7771\n",
      "Epoch 3/40\n",
      "899/899 [==============================] - 2s 2ms/step - loss: 0.1312 - binary_accuracy: 0.9610 - val_loss: 0.3464 - val_binary_accuracy: 0.8307\n",
      "Epoch 4/40\n",
      "899/899 [==============================] - 2s 2ms/step - loss: 0.1018 - binary_accuracy: 0.9679 - val_loss: 0.2906 - val_binary_accuracy: 0.8706\n",
      "Epoch 5/40\n",
      "899/899 [==============================] - 2s 2ms/step - loss: 0.0836 - binary_accuracy: 0.9733 - val_loss: 0.2397 - val_binary_accuracy: 0.9015\n",
      "Epoch 6/40\n",
      "899/899 [==============================] - 2s 2ms/step - loss: 0.0715 - binary_accuracy: 0.9765 - val_loss: 0.2000 - val_binary_accuracy: 0.9222\n",
      "Epoch 7/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0637 - binary_accuracy: 0.9794 - val_loss: 0.1739 - val_binary_accuracy: 0.9339\n",
      "Epoch 8/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0569 - binary_accuracy: 0.9813 - val_loss: 0.1517 - val_binary_accuracy: 0.9469\n",
      "Epoch 9/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0527 - binary_accuracy: 0.9820 - val_loss: 0.1306 - val_binary_accuracy: 0.9572\n",
      "Epoch 10/40\n",
      "899/899 [==============================] - 2s 2ms/step - loss: 0.0489 - binary_accuracy: 0.9834 - val_loss: 0.1284 - val_binary_accuracy: 0.9583\n",
      "Epoch 11/40\n",
      "899/899 [==============================] - 2s 2ms/step - loss: 0.0473 - binary_accuracy: 0.9843 - val_loss: 0.1276 - val_binary_accuracy: 0.9583\n",
      "Epoch 12/40\n",
      "899/899 [==============================] - 2s 2ms/step - loss: 0.0446 - binary_accuracy: 0.9845 - val_loss: 0.1194 - val_binary_accuracy: 0.9606\n",
      "Epoch 13/40\n",
      "899/899 [==============================] - 3s 3ms/step - loss: 0.0435 - binary_accuracy: 0.9861 - val_loss: 0.1141 - val_binary_accuracy: 0.9627\n",
      "Epoch 14/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0426 - binary_accuracy: 0.9859 - val_loss: 0.1139 - val_binary_accuracy: 0.9640\n",
      "Epoch 15/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0413 - binary_accuracy: 0.9863 - val_loss: 0.1083 - val_binary_accuracy: 0.9655\n",
      "Epoch 16/40\n",
      "899/899 [==============================] - 2s 2ms/step - loss: 0.0396 - binary_accuracy: 0.9874 - val_loss: 0.1068 - val_binary_accuracy: 0.9658\n",
      "Epoch 17/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0389 - binary_accuracy: 0.9870 - val_loss: 0.1056 - val_binary_accuracy: 0.9666\n",
      "Epoch 18/40\n",
      "899/899 [==============================] - 3s 3ms/step - loss: 0.0386 - binary_accuracy: 0.9875 - val_loss: 0.1048 - val_binary_accuracy: 0.9668\n",
      "Epoch 19/40\n",
      "899/899 [==============================] - 2s 2ms/step - loss: 0.0381 - binary_accuracy: 0.9876 - val_loss: 0.1062 - val_binary_accuracy: 0.9668\n",
      "Epoch 20/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0376 - binary_accuracy: 0.9872 - val_loss: 0.1025 - val_binary_accuracy: 0.9674\n",
      "Epoch 21/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0379 - binary_accuracy: 0.9872 - val_loss: 0.1005 - val_binary_accuracy: 0.9681\n",
      "Epoch 22/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0378 - binary_accuracy: 0.9881 - val_loss: 0.1010 - val_binary_accuracy: 0.9683\n",
      "Epoch 23/40\n",
      "899/899 [==============================] - 2s 2ms/step - loss: 0.0376 - binary_accuracy: 0.9878 - val_loss: 0.1034 - val_binary_accuracy: 0.9679\n",
      "Epoch 24/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0379 - binary_accuracy: 0.9874 - val_loss: 0.1013 - val_binary_accuracy: 0.9687\n",
      "Epoch 25/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0372 - binary_accuracy: 0.9871 - val_loss: 0.1042 - val_binary_accuracy: 0.9679\n",
      "Epoch 26/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0361 - binary_accuracy: 0.9882 - val_loss: 0.1056 - val_binary_accuracy: 0.9676\n",
      "Epoch 27/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0364 - binary_accuracy: 0.9880 - val_loss: 0.1044 - val_binary_accuracy: 0.9680\n",
      "Epoch 28/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0373 - binary_accuracy: 0.9881 - val_loss: 0.1001 - val_binary_accuracy: 0.9690\n",
      "Epoch 29/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0357 - binary_accuracy: 0.9879 - val_loss: 0.1061 - val_binary_accuracy: 0.9681\n",
      "Epoch 30/40\n",
      "899/899 [==============================] - 2s 2ms/step - loss: 0.0359 - binary_accuracy: 0.9883 - val_loss: 0.1050 - val_binary_accuracy: 0.9687\n",
      "Epoch 31/40\n",
      "899/899 [==============================] - 2s 2ms/step - loss: 0.0356 - binary_accuracy: 0.9880 - val_loss: 0.1016 - val_binary_accuracy: 0.9690\n",
      "Epoch 32/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0367 - binary_accuracy: 0.9882 - val_loss: 0.0999 - val_binary_accuracy: 0.9695\n",
      "Epoch 33/40\n",
      "899/899 [==============================] - 2s 2ms/step - loss: 0.0357 - binary_accuracy: 0.9883 - val_loss: 0.0977 - val_binary_accuracy: 0.9694\n",
      "Epoch 34/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0354 - binary_accuracy: 0.9880 - val_loss: 0.1043 - val_binary_accuracy: 0.9686\n",
      "Epoch 35/40\n",
      "899/899 [==============================] - 2s 2ms/step - loss: 0.0356 - binary_accuracy: 0.9880 - val_loss: 0.1018 - val_binary_accuracy: 0.9690\n",
      "Epoch 36/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0345 - binary_accuracy: 0.9884 - val_loss: 0.1094 - val_binary_accuracy: 0.9679\n",
      "Epoch 37/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0352 - binary_accuracy: 0.9889 - val_loss: 0.1035 - val_binary_accuracy: 0.9684\n",
      "Epoch 38/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0364 - binary_accuracy: 0.9878 - val_loss: 0.1009 - val_binary_accuracy: 0.9690\n",
      "Epoch 39/40\n",
      "899/899 [==============================] - 2s 3ms/step - loss: 0.0347 - binary_accuracy: 0.9891 - val_loss: 0.1023 - val_binary_accuracy: 0.9688\n",
      "Epoch 40/40\n",
      "899/899 [==============================] - 2s 2ms/step - loss: 0.0359 - binary_accuracy: 0.9888 - val_loss: 0.1055 - val_binary_accuracy: 0.9681\n",
      "225/225 [==============================] - 5s 19ms/step - loss: 0.1083 - accuracy: 0.9674 - precision_34: 0.9937\n",
      "INFO:tensorflow:Assets written to: /Users/badr/Documents/ETS/Hiv2021/PFE/VS/git/fake-news-detection/notebooks/../models/tensorflow/model_5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [10:37<00:00, 127.44s/it]\n"
     ]
    }
   ],
   "source": [
    "Tensorflow.train(embedding_dim = 32, max_features = 625, sequence_length = 125, epochs = 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7ff3094a9280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Found 8985 files belonging to 2 classes.\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.1043 - accuracy: 0.9688 - precision_30: 0.9946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:05<00:21,  5.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7ff338b1d5e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Found 8985 files belonging to 2 classes.\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.1130 - accuracy: 0.9674 - precision_31: 0.9950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:11<00:17,  5.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7ff320e8fa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Found 8983 files belonging to 2 classes.\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.1204 - accuracy: 0.9667 - precision_32: 0.9958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:16<00:10,  5.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7ff338b24e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Found 8983 files belonging to 2 classes.\n",
      "281/281 [==============================] - 4s 13ms/step - loss: 0.1207 - accuracy: 0.9663 - precision_33: 0.9953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:20<00:05,  5.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7ff30cb08310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Found 8983 files belonging to 2 classes.\n",
      "281/281 [==============================] - 4s 14ms/step - loss: 0.1025 - accuracy: 0.9685 - precision_34: 0.9953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:25<00:00,  5.17s/it]\n"
     ]
    }
   ],
   "source": [
    "Tensorflow.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.9951877236366272"
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tensorflow.precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.9675415277481079"
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tensorflow.accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing on an article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\" Members of Congress may use campaign funds to hire bodyguards, FEC rules\n",
    "(CNN) — Members of Congress can use campaign funds to hire bodyguards, federal election regulators ruled Thursday -- nearly three months after the violent January 6 siege on the US Capitol raised fresh concerns about lawmakers' safety.\n",
    "\n",
    "The 5-1 vote by the Federal Election Commission allows lawmakers to use donors' money for \"bona fide, legitimate, professional personal security\" against threats that arise as part of their jobs.\n",
    "\n",
    "The action came in response to a request from officials with the National Republican Congressional Committee and the National Republican Senatorial Committee and falls in line with previous FEC actions that allow politicians to use campaign money to upgrade security at their homes.\n",
    "But the commission spent hours of their online meeting tussling over how to properly define security personnel after Democratic lawyers raised the specter of some lawmakers using donors' money to pay right-wing militia members.\n",
    "\n",
    "In a Wednesday letter to the commission, Marc Elias and other attorneys representing Democratic campaign committees urged regulators to craft the rules narrowly so that \"campaign funds are not improperly used to fund groups organized to harass and intimidate political opponents.\"\n",
    "\n",
    "\"In the past election cycle, some individuals who are now Members of Congress displayed troubling ties to extremist groups, including some self-proclaimed 'militias,' such as the Proud Boys, the Oath Keepers, and the Three Percenters,\" the Democratic lawyers wrote. \"In some cases, these groups purported to provide 'security' at events attended by Congressional candidates and Members of Congress.\"\n",
    "\n",
    "One Democrat on the commission, Ellen Weintraub, said she was concerned about lawmakers operating at a far remove from their constituents and that untrained guards could improperly block the public from engaging with elected officials.\n",
    "\n",
    "\"I never thought of us as a country where the leadership of the country had to be surrounded by armed guards and ... needed to keep the public at arm's length,\" Weintraub said.\n",
    "\n",
    "But Jessica Furst Johnson, a lawyer representing the Republican campaign committees, said lawmakers have pressing security concerns.\n",
    "\n",
    "The threats they face, she retorted, do not involve \"people who are showing up at homes in the middle of the night to have a nice conservation about legislation. We are talking about situations where members are, unfortunately, feeling threatened with their children in their homes in the middle of the night.\" \"\"\".replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "' Members of Congress may use campaign funds to hire bodyguards, FEC rules (CNN) — Members of Congress can use campaign funds to hire bodyguards, federal election regulators ruled Thursday -- nearly three months after the violent January 6 siege on the US Capitol raised fresh concerns about lawmakers\\' safety.  The 5-1 vote by the Federal Election Commission allows lawmakers to use donors\\' money for \"bona fide, legitimate, professional personal security\" against threats that arise as part of their jobs.  The action came in response to a request from officials with the National Republican Congressional Committee and the National Republican Senatorial Committee and falls in line with previous FEC actions that allow politicians to use campaign money to upgrade security at their homes. But the commission spent hours of their online meeting tussling over how to properly define security personnel after Democratic lawyers raised the specter of some lawmakers using donors\\' money to pay right-wing militia members.  In a Wednesday letter to the commission, Marc Elias and other attorneys representing Democratic campaign committees urged regulators to craft the rules narrowly so that \"campaign funds are not improperly used to fund groups organized to harass and intimidate political opponents.\"  \"In the past election cycle, some individuals who are now Members of Congress displayed troubling ties to extremist groups, including some self-proclaimed \\'militias,\\' such as the Proud Boys, the Oath Keepers, and the Three Percenters,\" the Democratic lawyers wrote. \"In some cases, these groups purported to provide \\'security\\' at events attended by Congressional candidates and Members of Congress.\"  One Democrat on the commission, Ellen Weintraub, said she was concerned about lawmakers operating at a far remove from their constituents and that untrained guards could improperly block the public from engaging with elected officials.  \"I never thought of us as a country where the leadership of the country had to be surrounded by armed guards and ... needed to keep the public at arm\\'s length,\" Weintraub said.  But Jessica Furst Johnson, a lawyer representing the Republican campaign committees, said lawmakers have pressing security concerns.  The threats they face, she retorted, do not involve \"people who are showing up at homes in the middle of the night to have a nice conservation about legislation. We are talking about situations where members are, unfortunately, feeling threatened with their children in their homes in the middle of the night.\" '"
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7ff30deee4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "tf_model_path = os.path.join(\n",
    "                Tensorflow.model_path, 'tensorflow', 'model_1')\n",
    "\n",
    "model = tf.keras.models.load_model(tf_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff31a0943a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[0.0977672]], dtype=float32)"
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([text]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\" Nolte: Whites Excluded, Illegal Aliens Qualify for Oakland’s $500 Month Payout Program \n",
    "\n",
    "Oakland, California, Mayor Libby Schaaf (D) announced a program that offers poor minority families $500 a month. Poor white families are excluded for the sin of being white. However, illegal aliens qualify.\n",
    "\n",
    "Per the Daily Mail, “An estimated 10,000 of Oakland’s 435,000 population are white residents who live in poverty,” but they will receive nothing, and only because they are white.\n",
    "\n",
    "Here is how you qualify for Oakland’s no-questions-asked $500 a month:\n",
    "\n",
    "You must have at least one child\n",
    "Your income must be at or below 50 percent of Oakland’s median income\n",
    "You must not be white\n",
    "The excuse for excluding whitey, per the far-left Associate Press, is that “White households in Oakland on average make about three times as much annually than black households[.]”\n",
    "\n",
    "Yeah, but, um, 10,000 white households do not.\n",
    "\n",
    "Okay, but they are still white. Duh.\n",
    "\n",
    "The good news — if you’re a total lunatic — is that while poor whites are excluded based only on the fact they are white, illegal aliens do qualify for the $500 per month.  Per Yahoo, the $500 is not taxable “and undocumented and/or unsheltered individuals also qualify.”\n",
    "\n",
    "Let me run that Yahoo sentence through the Orwellian translator: “illegal aliens and the homeless also qualify.”\n",
    "\n",
    "Ah, but do white illegal aliens and white homeless people qualify?\n",
    "\n",
    "Oh, and how do you prove you qualify? Is a racist ID required?\n",
    "\n",
    "Do Asians qualify as “people of color,” or is this one more hate crime against them, just like all the other hate crimes against Asians that happen exclusively in Democrat-run cities?\n",
    "\n",
    "What about a white person who is both homeless and an illegal alien; would this person qualify?\n",
    "\n",
    "The city is going to try and get away with this blatant racism by claiming the fund being used for the $500 payouts is a private fund. We’ll see if that flies, not only with the people but with the Supreme Court.\n",
    "\n",
    "Oakland is a shithole city and one that has been run exclusively by Democrats for some 50 years. If there’s a racism problem in Oakland, if there’s a “systemic racism” problem in Oakland, let’s try to remember who’s been in charge of that system for a half century.\n",
    "\n",
    "The Daily Mail reports “Oakland’s homeless population rose by nearly 50 per cent between 2017 and 2019.” Well, with Democrats in charge for a half-century, whose fault is that? Out here in MAGA Land, in Rural America, we don’t have a homeless crisis.\n",
    "\n",
    "Oakland closed 2020 with its highest murder rate in eight years; 102 people killed. Well, whose fault is that? Out here in Trump Land we don’t have a gun violence problem (even though we all own guns).\n",
    "\n",
    "Last year, Oakland was named one of the most dangerous cities in America? Well, whose fault is that? Out here in Rural America, all of us Trumptards live in peace and brotherhood. No racial tensions. No riots. No mass shootings.\n",
    "\n",
    "There’s just no question that one of the primary motives behind excluding whites from this $500 a month is to deliberately gin up racial hate and racial division and racial tensions, which is something else that is almost exclusive to Democrat-run cities.\n",
    "\n",
    "Between the violence, the shitty schools, the deliberate gunning up of racial tensions, not to mention all the rioting led by the left-wing terrorists in Antifa and Black Lives Matter, these Democrat-run cities are deliberately tearing themselves apart.\n",
    "\n",
    "No sympathy here.\n",
    "\n",
    "You get what you vote for and the idiots of Oakland obviously enjoy racism and murder and poverty and chronic homelessness. They do keep voting for it.\n",
    "\n",
    "No skin off my nose.\n",
    "\n",
    "Life remains peaceful, clean, safe, colorblind, and serene in MAGA Country.\n",
    "\"\"\".replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.00042763]], dtype=float32)"
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([text]) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python388jvsc74a57bd0edd520d6644a321125cc4a079653ea19f3677dde8ec49922823a2d76c0a5a38b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}